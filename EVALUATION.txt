------------------------------------
| REGISTER ALLOCATION OPTIMIZATION |
------------------------------------

1. Scope

This implementation does not perform register allocation for global variables
and array locations. Moreover, I use a single live range per variable.

Coalescence is performed, but I figured it is already covered by the given
algorithm. At least for the single live range per variable scenario.

2. Registers used

In this implementation I use a set of 16 registers for variable allocation:
$t2 - $t10
$s0 - $s7

Registers $t0 and $t1 are reserved for intermediary operations and are never
used for long-term storage of a live range.

3. Caller/callee saving procedure

Registers from $t2 to $t10 are saved and restored by the caller before and
right after a function call. On the other hand, registers from $s0 to $s7 are
written to memory by the callee in its ENTER and restored back in this LEAVE
instructions.

When I first executed this optimization, the aforementioned procedure actually
increased the number of writes and reads from memory because of the
indiscriminate savings and loadings to and from memory at every function call.
To reduce the number of write and load operations, I keep a set of registers
used in a function and I only save and restore registers that are used inside
that function.

If a function being called has not been parsed yet (function definition delayed)
, I make no assumptions and I save all the registers that will be used in the
caller later (registers reserved for variables live after the function call)
before invoking the callee. In most of the cases, function definitions will be
 given before they are called by another function, therefore, this issue
 shouldn't happen often.

Also, I made sure that the set of registers used by a function is updated in
such a way that in the end it also includes any registers used by other
functions invoked within the former function's scope.

Finally, since the println function was hardcoded and no $t register is used in
it, I manually defined the set of registers used in that function to empty.

3. Choosing registers to allocate

I made a slight modification to the original algorithms to reduce register
clashing. Before I describe them, consider the following definitions

- Node: A variable's live range (sometimes I will abuse this definition and I
will use node and variable interchangeably. Hopefully, it will be clear from the
 context whenever I do so).
- AvoidSet: Set of registers that cannot be used by a node. Every node in the
graph has its own AvoidSet.
- PrefSet: Set of registers that should be given preference by a node. Every
node in the graph has its own PrefSet.

a. Constructing the interference graph

1. Initialize the PrefSet of each node with a full set of registers.
2. Proceed with the original algorithm.
3. Whenever a CALL instruction is processed, for every variable in LiveNow set
at that point, remove the registers used in the function being called from
those variables' PrefSet.

In the end, the PrefSet for each node will contain registers that are not used
by functions called when the node's variable is live. If we can allocate
some nodes to one of the registers in their PrefSet, this will reduce the number
 of caller saves/loads needed at function calls.

As it will be clear next, even if this PrefSet for a node is not empty, it's not
guaranteed that we will be able to use a register from it for that node.

b. Coloring the graph

Let K be the max number of registers to use and RSet be the set of all K
registers.

1. Initialize the AvoidSet of each node with an empty set of registers.
2. REPEAT
3.   get node with highest cost from the list of nodes with < K neighbors
4.   remove node from the graph
5.   IF node's PrefSet - nodes's AvoidSet is empty THEN
6.	 	AvailableSet = RSet - nodes's AvoidSet
7.   ELSE
8.      AvailableSet = node's PrefSet - nodes's AvoidSet
9.   END
10.  assign any register from AvailableSet to the node
11.  add the chosen register to the AvoidSet of every neighbor of the node
12.  UNTIL
13.  ... // Equals to the original algorithm

Let's go over the modifications introduced to understand the intuition behind
them.

In line 3, instead of picking an arbitrary node with fewer than K neighbors
from the graph, I choose the one with highest cost to increase the likelihood of
 being able to allocate high cost variables to one of the registers in their
 PrefSet. Notice that as I color the graph, I include elements to some nodes'
 AvoidSet. If we delay the evaluation of a node, we might end up with a
 situation where all the registers in its PrefSet are also in its AvoidSet (line
  6), forcing us to pick a register that will be stored/retrieved from memory by
   a the caller at some point. Processing the nodes with higher cost first will
   reduce the amount of times this issue happens with high cost variables.

Finally, line 11 is necessary so we don't end up allocating the same register
for two neighbor live ranges.

At the end of this algorithm, the variables will already be informed about the
registers they must use in the generated assembly code.


4. Cost of a variable

I compute the cost of a variable during my code generation phase. Therefore,
over the AST. I used the following atomic instruction costs:

- Cost at the AST root: 1
- Cost in a single instruction: 1
- Cost in a branch: 1
- Cost in a loop initialization: 1
- Cost in a loop update and evaluation: 10
- Cost in a loop body: 10

The cost is processed recursively, thus variables in a nested scope will yield
the cost of the outer scope multiplied by the incurring cost of the instructions
 they are in in the inner scope.

5. Type conversion

When we are working writing and loading values to and from memory, storing a
char in a register is handled directly by the sb,lb instructions. When we
perform register allocation, on the other hand, there is no instruction to load
a char immediately or to move just the least significant byte with signal
 preservation between registers. Therefore, whenever we are loading a value
 to a char variable stored in a register, we need to make sure to mimic what lb
 does under the hood so that we can guarantee we are not breaking type
 conversion and overflow handling.

To do that, after loading a value to a register (reg) reserved to hold the value
 of a char variable, I add the following extra code to perform sign extension:

sll reg, reg, 24
sra reg, reg, 24

6. Coalescence

I realized that the algorithm provided in the slides already handles coalescence
for the case in which we use one live range per variable. This is because the
LiveNow set is updated only after the edges had been created in a specific
iteration. Therefore, when edges for an instruction of the type y = x are
created, if that's the last occurrence of x, x will not be in the LiveNow set
yet, which will prevent y and x to be connected in the graph, and therefore,
they will be able to share a register.

Whenever two variables coalesce, this might result in an instruction like

move reg, reg

because both variables can share the same register. This is a void instruction
that do not generate in the final assembly code.

--------------------------
| ORDER OF OPTIMIZATIONS |
--------------------------

I process register allocation after local and global optimization. This is a
different kind of optimization as it does not work by removing intermediary
instructions but machine code. Eliminating intermediary instructions first, by
the local and global optimization procedures, might reduce the number of
registers actually needed, improving the overall performance of the compiler.

--------------------------
| IMPLEMENTATION DETAILS |
--------------------------

Not to increase too much the compilation overhead, I implemented the set of
nodes to color and to spill as a max and min heap respectively. Therefore,
getting a node with highest/lowest cost will be O(logn) instead of O(n) which is
 what would get if I worked with a linked list.

---------------
| Experiments |
---------------

The programs used in this section are in the directory eval/a3.

- Program 1

This program is the 4th program I experimented with in the previous assignment.
It consists of a merge of 3 other programs that were individually coded to
explore gains of specific types of local and global optimizations. I chose this
program to start this section to check how much more improvement register
allocation can bring to the final machine code.

Below are the results of register allocation optimization compared to what I got
 previously.

Before Optimization
Stats -- #instructions : 318
         #reads : 113  #writes 102  #branches 23  #other 80

After Optimization(local + global)
Stats -- #instructions : 145
         #reads : 29  #writes 16  #branches 22  #other 78

After Optimization(register allocation only)
Stats -- #instructions : 128
         #reads : 6  #writes 5  #branches 23  #other 94

After Optimization(local + global + register allocation)
Stats -- #instructions : 111
         #reads : 6  #writes 5  #branches 22  #other 78

This is an incredible result. Register allocation by itself was able to
cause a reduction of 95% write and load instructions compared to the
unoptimized generated code, surpassing local + global optimization performance
in terms of these memory intensive instructions. Compared to the code optimized
by local and global methods, it represents a reduction of 79% in write and load
instructions.

It's important to highlight, however, that register allocation increases the
number of other instructions, which involves operations with registers. Local and
 global optimizations can help with this by eliminating unnecessary
 intermediary code, which, by consequence, reduces the number of instructions
 and, sometimes, the number of registers needed to be allocated. We see
 that the final optimized code (after the application of all 3 types of
 optimizations implemented) is more efficient than the original code in terms
  of all kinds of instructions: write, load, branches and other.

- Program 2

Another function 8 registers in a function and 8 registers in another function.

- Program 3

16 registers per function.

- Program 4

16 registers needed in a function and 4 registers needed in another function.
Check if it allocates the costlier variables first.

- Program 5

Check runtime


-----------------------




- Program 5

The most costly of the three algorithms implemented is dead code elimination
because it requires liveness analysis and the information is not constrained to
a single block. This program consists of a series of dead instructions
inside nested loops (therefore, multiple blocks) to allow us to compare how the
optimization affects the running time of the compiler.

Before Optimization
Stats -- #instructions : 110571
         #reads : 38902  #writes 36855  #branches 10238  #other 24576

Running time (10 independent executions): 0.21 +|- 0.035 ms

After Optimization(local + global optimization)
Stats -- #instructions : 47100
         #reads : 10238  #writes 6143  #branches 8191  #other 22528

Running time (10 independent executions): 1 +|- 0.04 ms

Local and global optimizations were able to reduce by a large amount the number
of instructions in this sample program. 76% reduction in read, 83% in write and
20% branch instructions. All of this, however, at a cost of taking almost 5x
more milliseconds to generate the final assembly code.









