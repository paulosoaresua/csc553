-----------------------------
| OPTIMIZATIONS IMPLEMENTED |
-----------------------------

1. Peephole

Below are the kinds of patterns I found in the generated code that can be
optimized by a peephole strategy.

a) Jump to next instruction

The code generation for boolean expressions was implemented recursively,
passing a "true" and "false" label to jump to. Because the loop evaluation is
the last instruction in a block, we always get the following pattern

COND_JUMP i > _tmp1 -> L0
JUMP L2
LABEL L2

where L0 is the label in the loop body's header. Therefore, there's an
unnecessary jump to the next instruction that can be safely removed.

This optimization results in 1 less branch instruction per loop instruction (not
 iteration).

b) Jump after conditionals

The code generated for a conditional instruction is typically as follows

COND_JUMP _tmp0 > _tmp1 -> L0
JUMP L2
LABEL L0

We can get rid of the jump in the second line by inverting the boolean operator
in the COND_JUMP instruction and jumping to L2 in case of success. The example
above after this optimization would then be

COND_JUMP _tmp0 <= _tmp1 -> L2
LABEL L0

This optimization results in 1 less branch instruction per conditional
instruction, regardless of the existence of an "else" statement.

c) Null and duplicate assignments

Immediate duplicate assignment instructions and assignments to the same variable
 are removed by this optimization. For instance,

 x = x; // Null assignment
 x = y;
 x = y; // Duplicate assignment

This optimization results in 1 less read and write instruction per null or
duplicate immediate assignment instructions.

Note: duplicate assignments that do not show up immediately after one another
are not removed by this optimization.

d) Immediate temporaries

The usage of temporary was widely used for code generation, which produces a
series of instructions where a value is assigned to a temporary and the next
immediate instruction assigns this temporary to a local/global variable. For
instance,

ASSIGN _tmp0 = constant(1)
ASSIGN x = _tmp0

This optimization removes these temporary allocations by assigning the RHS
directly to the variable of interest

ASSIGN x = constant(1)

This kind of copy is however constrained to temporary variables. The
instructions below won't be optimized by this approach as x is not a temporary.
 These kind of instructions will be handled by the copy propagation optimization
 instead.

ASSIGN x = constant(1)
ASSIGN y = x

One could argue that copy propagation will already handle this case, and,
therefore, it is redundant to do this as a peephole optimization. However, copy
 propagation only works on ASSIGN instructions and this peephole optimization is
 more general. Consider the following code snippet

ASSIGN _tmp0 = constant(1)
ASSIGN x = _tmp0
ASSIGN _tmp0 = constant(2)
ASSIGN y = _tmp0
BINARY_OPERATION _tmp0 = x ? y
ASSIGN z = _tmp0

Copy propagation will turn dead the ASSIGN instructions to temporaries
but not the assignment in the BINARY_OPERATION instruction. This peephole
optimization, on the other hand, gives us the following optimized code

ASSIGN x = constant(1)
ASSIGN y = constant(2)
BINARY_OPERATION z = x ? y

This optimization results in 1 less read and write instructions per any
instruction that contains a variable definition. They are:

ASSIGN
BINARY_OPERATION
UMINUS
RETRIEVE
DEREF

2. Copy Propagation

The copy propagation optimization implemented here copies constants or
variables to other variables via the transitivity property of assignment
operations.

We do not propagate a copy if the LHS variable type is different from the RHS
variable type and the RHS type is different from the original variable type, as
this could bypass type conversion. For instance,

int x, y;
char z;

x = 255;
z = x;
y = z;

In this example, since y's type is different from z's type and z's type is
different from 255's type, we do not copy 255 to y.

Copy propagation, per se, typically do not remove instructions, but it creates
instructions that will be detected as dead by liveness analysis. However,
there's a simple pattern that can be immediately removed and this implementation
 covers it: we remove assignment instructions if the LHS and the RHS map to the
 same variable, where the definition of mapping is such that v maps to u if v
  was copied from u, otherwise, v maps to itself. For instance,

int x, y, z

x = randint();
y = x;
z = y;
x = z;

Since both x and z map to x, we mark the last instruction as dead when doing
copy propagation.

3. Liveness analysis and dead code elimination

This optimization performs linveness analysis over the basic blocks and the
elimination process proceeds by analysing the blocks backwards to find dead
instructions. This process repeats until no more changes are detected.

--------------------------
| ORDER OF OPTIMIZATIONS |
--------------------------

For local optimization, I chose to run peephold followed by copy
propagation. While the order of optimization does not affect the final reduction
 in number of executed instruction, by doing peephole first, we reduce the
 number of copies to keep track of in the copy propagation due to temporary
 assignments.

If local and global optimizations are required, local optimization is performed
first as copy propagation and peephole can give rise to dead code, that can be
further removed by dead code elimination.

--------------------------
| IMPLEMENTATION DETAILS |
--------------------------

In my implementation, a call to a function starts a new basic block that has
this call instruction as a leader.

Next, in code propagation, I only keep track of the original variable in the the
chain, therefore, I don't need to keep track of a list of copies when replacing
the RHS variable in an assignment with the variable it was copied from. For
instance,

x = randint();
y = x;
z = y;
x = z;

is implemented like

x.copied_from = NULL;
y.copied_from = x;
z.copied_from = y.copied_from = x;
x.copied_from = z.copied_from = x; // Marked dead by copy propagation null
								   // assignment detection

Furthermore, in liveness analysis, once the in and out sets are found, I erase
the def/use sets in the blocks to save memory space.

Finally, I used bit array to implement a set. I represent a bit array using an
integer, therefore, each set partition can hold up to 32 elements. A set can
have up to 2^64 partitions and, thus, up to 32*(2^64) elements.

---------------
| Experiments |
---------------

The programs used in this section are in the directory eval/.

- Program 1

This program explores the effect of peephole on code optimization. It contains
each one of the instructions that can be optimized by the peephole approach.
By suppressing copy propagation, we can see that all credits on the reduction
of number of write and branch instructions goes to peephole in this
sample program. Here are the results reported by spim before and after
optimization:

Before Optimization
Stats -- #instructions : 178
         #reads : 60  #writes 47  #branches 17  #other 54

After Optimization (peephole only)
Stats -- #instructions : 153
         #reads : 48  #writes 35  #branches 16  #other 54

After Optimization (peephole only + copy propagation)
Stats -- #instructions : 153
         #reads : 27  #writes 35  #branches 16  #other 75

Considering only peephole: 20% reduction in the number of read instructions and
25% reduction in the number of write instructions due to optimizations c and d.
And 5% reduction in the number of branch instructions due to optimizations a and
 b.

- Program 2

This programs explores the effect of copy propagation on code optimization. It
contains a series of consecutive assignment instructions that can be propagated
by transitivity. Discounting the single write instruction optimized by peephole
(optimization d), the expressive reduction in the number of read instructions
is all due to copy propagation.

Before Optimization
Stats -- #instructions : 61
         #reads : 23  #writes 23  #branches 3  #other 12

After Optimization
Stats -- #instructions : 59
         #reads : 3  #writes 22  #branches 3  #other 31

87% reduction in the number of read instructions.

- Program 3

This programs explores the effect of dead code elimination on a program with
three blocks comprised of instructions that are all dead.

Before Optimization
Stats -- #instructions : 85
         #reads : 25  #writes 25  #branches 7  #other 28

After Optimization
Stats -- #instructions : 47
         #reads : 7  #writes 6  #branches 7  #other 27

72% reduction in the number of read instructions and 76% reduction in the number
 of write instructions. The resultant optimized code does not contain any
 assignment instructions but the ones necessary to assign a constant to a
 temporary variable that is, in turn, used as parameter to the println function
  call.

- Program 4

This program is a merge of the previous 3 programs. I aim to explore the
contribution of each optimization individually and as a whole.

Before Optimization
Stats -- #instructions : 318
         #reads : 113  #writes 102  #branches 23  #other 80

After Optimization (peephole only)
Stats -- #instructions : 271
         #reads : 90  #writes 79  #branches 22  #other 80

After Optimization (peephole + copy propagation)
Stats -- #instructions : 271
         #reads : 42  #writes 79  #branches 22  #other 128

After Optimization (dead code elimination only)
Stats -- #instructions : 218
         #reads : 65  #writes 52  #branches 23  #other 78

After Optimization(local + global optimization)
Stats -- #instructions : 145
         #reads : 29  #writes 16  #branches 22  #other 78


The more we use combined optimization methods, the more instructions we can
discard in the code. One thing to notice here is the effect of local
optimization followed by a global one. The copy propagation process created some
 dead instructions that could be later removed by dead code elimination,
 causing a reduction of 65% in the number of read instructions (from 65 to 29)
 and 70% in the number of dead instructions (from 52 to 16) compared to the
 number of read/write instructions after dead code elimination alone.

- Program 5

The most costly of the three algorithms implemented is dead code elimination
because it requires liveness analysis and the information is not constrained to
a single block. This program consists of a series of dead instructions
inside nested loops (therefore, multiple blocks) to allow us to compare how the
optimization affects the running time of the compiler.

Before Optimization
Stats -- #instructions : 110571
         #reads : 38902  #writes 36855  #branches 10238  #other 24576

Running time (10 independent executions): 0.21 +|- 0.035 ms

After Optimization(local + global optimization)
Stats -- #instructions : 47100
         #reads : 10238  #writes 6143  #branches 8191  #other 22528

Running time (10 independent executions): 1 +|- 0.04 ms

Local and global optimizations were able to reduce by a large amount the number
of instructions in this sample program. 76% reduction in read, 83% in write and
20% branch instructions. All of this, however, at a cost of taking almost 5x
more milliseconds to generate the final assembly code.









